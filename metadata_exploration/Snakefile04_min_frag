configfile: "/vsc-hard-mounts/leuven-data/351/vsc35107/master_thesis/workflow_new/config.yaml"

sample_names, = glob_wildcards("/lustre1/project/stg_00079/students/tingting/data/sun/snap2_allfragments/000fragments/{name}.fragments.Mic.tsv.gz")

import snapatac2 as snap
import os
import random
import multiprocessing as mp
import anndata

rule all:
    input:
        all_min_fragments="all_min_fragments_0.csv",

rule import_data_temp:
    input:
        # check
        frags="/lustre1/project/stg_00079/students/tingting/data/sun/snap2_allfragments/000fragments/{name}.fragments.Mic.tsv.gz",   
    output:
        h5ad="/lustre1/scratch/351/vsc35107/temp_h5ad/{name}.h5ad"
    run:
        snap.pp.import_data(
            input.frags,
            file=output.h5ad,
            chrom_sizes=snap.genome.hg38, 
            min_num_fragments=0,
            sorted_by_barcode=False,)

rule min_fragments:
    input:
        h5ad="/lustre1/scratch/351/vsc35107/temp_h5ad/{name}.h5ad",
    output:
        min_num_fragments="/lustre1/scratch/351/vsc35107/temp_csv/{name}.csv"
    run:
        import csv
        dat=anndata.read_h5ad(input.h5ad)
        min_num_fragments= min(dat.obs['n_fragment']) 
        num_cell=dat.obs.shape[0]
        with open(output.min_num_fragments, 'w') as f:
                writer=csv.writer(f)
                writer.writerow([wildcards.name, min_num_fragments, num_cell])        

rule converge:
    input:
        min_num_fragments=expand("/lustre1/scratch/351/vsc35107/temp_csv/{name}.csv",name=sample_names),
    output:
        all_min_fragments="all_min_fragments_0.csv"
    shell:
        """
        rm -f {output.all_min_fragments}
        cat {input.min_num_fragments} >> {output.all_min_fragments}
        """

